# 베이스라인

# !pip install dabl
!pip install joblib==1.3
!pip install -q pycaret
!pip install -q catboost
!pip install --upgrade -q xgboost
!pip install -q dabl
!pip install -q scikit-optimize
!pip install -q autogluon
from pycaret.regression import *
import pandas as pd
import numpy as np
import os

import xgboost as xgb
import lightgbm as lgb
import xgboost as xgb
import lightgbm as lgb
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, LassoCV, LassoLars
from sklearn.linear_model import PassiveAggressiveRegressor, ARDRegression, RidgeCV, ElasticNetCV
from sklearn.linear_model import TheilSenRegressor, RANSACRegressor, HuberRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.svm import SVR, LinearSVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor
from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.cross_decomposition import PLSRegression
from catboost import CatBoost, CatBoostRegressor, CatBoostClassifier
from catboost import Pool
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from lightgbm import LGBMRegressor
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split
from skopt import BayesSearchCV
from autogluon.tabular import TabularDataset, TabularPredictor

path = ('/content/drive/MyDrive/9.파이널프로젝트/회귀 데이터/')


train = pd.read_csv( os.path.join(path,'train.csv'), index_col='id' )
test  = pd.read_csv( os.path.join(path,'test.csv'), index_col='id' )
submission = pd.read_csv( os.path.join(path,'sample_submission.csv'), index_col='id' )

train.shape, test.shape, submission.shape

train.head(3)

submission.head(3)

# 컬럼 설명 표
'''
- Clonesize m2: 밭에서의 평균 블루베리 클론 크기 (10~40)
- Honeybee bees/m2/min: 밭에서의 꿀벌 밀도 ( 0.00 ~ 1.84)
- Bumbles bees/m2/min: 밭에서의 범블벌 밀도 ( 0.00 ~ 0.58)
- Andrena bees/m2/min: 밭에서의 안드레나 벌 밀도 ( 0.00 ~ 0.75)
- Osmia bees/m2/min: 밭에서의 오스미아 벌 밀도 ( 0.00 ~ 0.75)
- MaxOfUpperTRange ℃: 꽃 피는 계절 중 일일 기온 최고 기록 ( 69.70 ~ 94.60)
- MinOfUpperTRange ℃: 꽃 피는 계절 중 일일 기온의 최저 기록 (39.00 ~ 57.20)
- AverageOfUpperTRange ℃: 꽃 피는 계절 중 기온의 평균 (58.20 ~ 79.00)
- MaxOfLowerTRange ℃: 하층 일일 기온의 최고 기록 (50.20 ~ 68.20)
- MinOfLowerTRange ℃: 하층 일일 기온의 최저 기록 (24.30 ~ 33)
- AverageOfLowerTRange ℃: 하층 일일 기온의 평균 (41.20 ~ 55.90)
- RainingDays Day: 꽃 피는 계절의 강수량 (1~34)
- AverageRainingDays Day: 전체 꽃 피는 계절의 평균 강수일 수 (0.06 ~ 0.56)

'''

train.info()

submission.info()

import matplotlib.pyplot as plt
import seaborn as sns

%matplotlib inline

sns.displot(train['yield']) # 정규분포모양 정규분포를 따르는듯 ?

sns.displot(train['honeybee'], color = 'red')

from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split

X = train.drop(['yield'], axis = 1)
y = train['yield']
X,y

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=0.9)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

model = DecisionTreeRegressor()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)


from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error

print('mae_score :',mae(y_test, y_pred))
